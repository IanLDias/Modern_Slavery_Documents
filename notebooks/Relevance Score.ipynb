{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Need to run !python -m spacy download en_core_web_sm\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path as pathl\n",
    "import sys, os, re\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append relevant file paths\n",
    "new_path = pathl('.')\n",
    "parent = new_path.resolve().parent\n",
    "sys.path.append(str(parent))\n",
    "from pdf_parser import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = parent / 'Data'\n",
    "def get_text(filename):\n",
    "    'Return text from a filename'\n",
    "    pdf_file = data_path / filename\n",
    "    text_dict = pipeline(filepath = str(pdf_file))\n",
    "    text = list(text_dict.values())\n",
    "    text = sum(text, [])\n",
    "    text = [sentence.strip() for sentence in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~\\n'\n",
    "def process_text(text):\n",
    "    '''Remove stopwords, punctuation and add the remaining to a dictionary with num occurances as values. \n",
    "    Returns word frequencies'''\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    \n",
    "    stopwords = list(STOP_WORDS)\n",
    "    word_frequencies = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in stopwords:\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "                    \n",
    "    return word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if last file path in sys is the root folder\n",
    "current_dir = os.walk(sys.path[-1] + '/Data')\n",
    "all_text = []\n",
    "for file in next(current_dir)[-1]:\n",
    "    try:\n",
    "        text = get_text(file)\n",
    "        all_text.append(process_text(text))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': 1,\n",
       " '+44': 1,\n",
       " '0': 1,\n",
       " '1455': 1,\n",
       " '558': 1,\n",
       " '600': 1,\n",
       " 'Registered': 1,\n",
       " 'En': 1,\n",
       " 'gland': 1,\n",
       " '1932827': 1,\n",
       " 'ered': 1,\n",
       " 'Office': 2,\n",
       " 'Hunter': 1,\n",
       " 'Boulevard': 1,\n",
       " '   ': 1,\n",
       " 'Magna': 1,\n",
       " 'Park': 1,\n",
       " 'Lutterworth': 1,\n",
       " 'LE17': 1,\n",
       " '4XN': 1,\n",
       " 'England': 1,\n",
       " 'Modern': 4,\n",
       " 'Slavery': 5,\n",
       " 'Human': 3,\n",
       " 'Trafficking': 2,\n",
       " 'Statement': 1,\n",
       " '2019': 1,\n",
       " 'Organisation': 1,\n",
       " 'Structure': 1,\n",
       " 'VWR': 11,\n",
       " 'International': 6,\n",
       " 'Ltd': 5,\n",
       " 'employs': 1,\n",
       " '782': 1,\n",
       " 'associates': 4,\n",
       " 'UK': 2,\n",
       " 'Situated': 1,\n",
       " 'Leicestershire': 1,\n",
       " 'Customer': 1,\n",
       " 'Service': 1,\n",
       " 'Centre': 1,\n",
       " 'purpose': 1,\n",
       " '-built': 1,\n",
       " 'warehouse': 1,\n",
       " '1985': 1,\n",
       " 'continued': 1,\n",
       " 'grow': 1,\n",
       " 'welcomed': 1,\n",
       " 'Jencons': 1,\n",
       " 'Lab3': 1,\n",
       " 'Basan': 1,\n",
       " 'Peqlab': 1,\n",
       " 'Hichrom': 1,\n",
       " 'Therapak': 1,\n",
       " 'meant': 1,\n",
       " 'able': 2,\n",
       " 'consistently': 1,\n",
       " 'provide': 2,\n",
       " 'unmatched': 1,\n",
       " 'product': 1,\n",
       " 'choice': 1,\n",
       " 'customers': 1,\n",
       " 'services': 1,\n",
       " 'include': 1,\n",
       " 'custom': 1,\n",
       " 'manufacturing': 1,\n",
       " 'support': 1,\n",
       " 'research': 2,\n",
       " 'laboratory': 1,\n",
       " 'operations': 1,\n",
       " '2017': 1,\n",
       " 'acquired': 1,\n",
       " 'Avantor': 5,\n",
       " 'vertically': 1,\n",
       " 'integrated': 1,\n",
       " 'global': 2,\n",
       " 'supplier': 1,\n",
       " 'discovery': 2,\n",
       " '-to': 1,\n",
       " '-delivery': 1,\n",
       " 'solutions': 2,\n",
       " 'life': 1,\n",
       " 'sciences': 1,\n",
       " 'advanced': 1,\n",
       " 'technologies': 1,\n",
       " 'industries': 1,\n",
       " '™': 2,\n",
       " 's': 3,\n",
       " 'expansive': 1,\n",
       " 'channel': 1,\n",
       " 'access': 2,\n",
       " 'deep': 1,\n",
       " 'customer': 1,\n",
       " 'relationships': 1,\n",
       " 'strengthens': 1,\n",
       " 'abilities': 1,\n",
       " 'adding': 1,\n",
       " 'vital': 1,\n",
       " 'new': 2,\n",
       " 'dimension': 1,\n",
       " 'scope': 1,\n",
       " '-from': 1,\n",
       " 'delivery': 1,\n",
       " 'statement': 1,\n",
       " 'accordance': 1,\n",
       " 'section': 1,\n",
       " '54': 1,\n",
       " '6': 1,\n",
       " 'Act': 2,\n",
       " '2015': 1,\n",
       " ' ': 4,\n",
       " 'aims': 1,\n",
       " 'ensure': 1,\n",
       " 'zero': 1,\n",
       " 'slavery': 2,\n",
       " 'human': 2,\n",
       " 'trafficking': 2,\n",
       " 'taking': 1,\n",
       " 'place': 1,\n",
       " 'organisation': 3,\n",
       " 'supply': 1,\n",
       " 'chain': 1,\n",
       " 'policy': 1,\n",
       " 'sets': 1,\n",
       " 'steps': 1,\n",
       " 'taken': 1,\n",
       " 'achieve': 1,\n",
       " 'aim': 1,\n",
       " 'Steps': 1,\n",
       " 'Prevention': 1,\n",
       " 'committed': 1,\n",
       " 'acting': 1,\n",
       " 'ethically': 1,\n",
       " 'integrity': 1,\n",
       " 'business': 1,\n",
       " 'dealings': 1,\n",
       " 'reflected': 1,\n",
       " 'page': 1,\n",
       " '10': 1,\n",
       " 'Code': 3,\n",
       " 'Conduct': 2,\n",
       " 'associate': 3,\n",
       " 'expected': 1,\n",
       " 'read': 1,\n",
       " 'sign': 1,\n",
       " 'refresher': 1,\n",
       " 'training': 3,\n",
       " 'session': 1,\n",
       " 'issued': 1,\n",
       " 'year': 2,\n",
       " 'complete': 1,\n",
       " 'implemented': 2,\n",
       " 'Ethical': 2,\n",
       " 'Trading': 2,\n",
       " 'Policy': 1,\n",
       " 'reinforcing': 1,\n",
       " 'company': 3,\n",
       " 'principles': 1,\n",
       " 'based': 1,\n",
       " 'internationally': 1,\n",
       " 'accepted': 1,\n",
       " 'standards': 1,\n",
       " 'listed': 1,\n",
       " 'Initiative': 1,\n",
       " 'B': 1,\n",
       " 'ase': 1,\n",
       " 'financial': 1,\n",
       " 'program': 2,\n",
       " 'raise': 1,\n",
       " 'awareness': 1,\n",
       " 'addition': 1,\n",
       " 'published': 1,\n",
       " 'Home': 1,\n",
       " 'Awareness': 1,\n",
       " 'Victim': 1,\n",
       " 'Identification': 1,\n",
       " 'Guidance': 1,\n",
       " 'booklet': 1,\n",
       " 'intranet': 1,\n",
       " 'available': 1,\n",
       " 'employees': 1,\n",
       " 'view': 1,\n",
       " 'carry': 1,\n",
       " 'checks': 1,\n",
       " 'individual': 1,\n",
       " 'comes': 1,\n",
       " 'work': 1,\n",
       " 'check': 1,\n",
       " 'bank': 1,\n",
       " 'account': 1,\n",
       " 'joint': 1,\n",
       " 'names': 1,\n",
       " 'request': 1,\n",
       " 'originals': 1,\n",
       " 'passport': 1,\n",
       " 'Right': 1,\n",
       " 'Work': 1,\n",
       " 'documentation': 1,\n",
       " 'encouraged': 1,\n",
       " 'report': 3,\n",
       " 'concerns': 2,\n",
       " 'treatment': 2,\n",
       " 'fellow': 1,\n",
       " 'line': 1,\n",
       " 'manager': 1,\n",
       " 'Resources': 1,\n",
       " 'department': 1,\n",
       " 'ensures': 1,\n",
       " 'feel': 1,\n",
       " 'prohibited': 1,\n",
       " 'law': 3,\n",
       " 'including': 1,\n",
       " 'nd': 1,\n",
       " 'threat': 1,\n",
       " 'repercussion': 1,\n",
       " 'Œ': 1,\n",
       " 'providing': 1,\n",
       " 'essential': 1,\n",
       " 'guidelines': 1,\n",
       " 'understand': 1,\n",
       " 'responsibilities': 1,\n",
       " 'obligations': 1,\n",
       " 'comply': 1,\n",
       " 'advise': 1,\n",
       " 'management': 1,\n",
       " 'compliance': 1,\n",
       " 'Associates': 1,\n",
       " 'means': 1,\n",
       " 'Associate': 1,\n",
       " 'Hotline': 1,\n",
       " 'confidentially': 1,\n",
       " 'anonymously': 1,\n",
       " 'theft': 1,\n",
       " 'fraud': 1,\n",
       " 'workplace': 1,\n",
       " 'violence': 1,\n",
       " 'conflicts': 1,\n",
       " 'interest': 1,\n",
       " 'accounting': 1,\n",
       " 'internal': 1,\n",
       " 'control': 1,\n",
       " 'issues': 1,\n",
       " 'violations': 1,\n",
       " 'Ethics': 1,\n",
       " 'Finance': 1,\n",
       " 'Infrastructure': 1,\n",
       " 'Director': 1}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
