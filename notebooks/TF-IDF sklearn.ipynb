{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from pathlib import Path as pathl\n",
    "from pdf_parser import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append relevant file paths\n",
    "new_path = pathl('.')\n",
    "parent = new_path.resolve().parent\n",
    "sys.path.append(str(parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.walk(sys.path[-1] + '/Data/downloaded_files')\n",
    "files = []\n",
    "for file in current_dir:\n",
    "    files.append(file[-1])\n",
    "files = sum(files, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = parent / 'Data/downloaded_files'\n",
    "def get_text(filename):\n",
    "    'Return text from a filename'\n",
    "    pdf_file = data_path / filename\n",
    "    text_dict = pipeline(filepath = str(pdf_file))\n",
    "    text = list(text_dict.values())\n",
    "    text = sum(text, [])\n",
    "    text = [sentence.strip() for sentence in text]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def lemmatizer(text):\n",
    "    'Lemmatizes text'\n",
    "    doc = nlp.pipe(text)\n",
    "    lemmatized = []\n",
    "    for sentence in doc:\n",
    "        sent = []\n",
    "        for word in sentence:\n",
    "            if str(word) in punctuation:\n",
    "                continue\n",
    "            lemma = word.lemma_.strip() \n",
    "            sent.append(lemma)\n",
    "        \n",
    "        lemmatized.append(' '.join(sent))\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n",
      "PdfReadWarning: Superfluous whitespace found in object header b'2' b'0' [pdf.py:1666]\n",
      "PdfReadWarning: Superfluous whitespace found in object header b'3' b'0' [pdf.py:1666]\n",
      "PdfReadWarning: Superfluous whitespace found in object header b'30' b'0' [pdf.py:1666]\n",
      "PdfReadWarning: Superfluous whitespace found in object header b'28' b'0' [pdf.py:1666]\n",
      "PdfReadWarning: Superfluous whitespace found in object header b'32' b'0' [pdf.py:1666]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "corpus = []\n",
    "\n",
    "for file in files[:10]:\n",
    "    if file[-3:] == 'pdf':\n",
    "        text = get_text(file)\n",
    "        text = text.split('.')\n",
    "        lemmatized = lemmatizer(text)\n",
    "        corpus.append(' '.join(lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [i for i in corpus if len(i) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vectorizer.fit_transform(corpus)\n",
    "dense = model.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = [cosine_similarity(model_1, model_2) for model_1, model_2 in list(combinations_with_replacement(dense, 2))]\n",
    "similarity = [similarity[i][0][0] for i in range(len(similarity))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = np.array(similarity)\n",
    "similarity = np.round(similarity, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_of_pdfs = list(zip(list(combinations_with_replacement(range(0,6), 2)), similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0), 1.0),\n",
       " ((0, 1), 0.68),\n",
       " ((0, 2), 0.55),\n",
       " ((0, 3), 0.55),\n",
       " ((0, 4), 0.6),\n",
       " ((0, 5), 0.69),\n",
       " ((1, 1), 1.0),\n",
       " ((1, 2), 0.6),\n",
       " ((1, 3), 0.43),\n",
       " ((1, 4), 0.55),\n",
       " ((1, 5), 0.62),\n",
       " ((2, 2), 1.0),\n",
       " ((2, 3), 0.37),\n",
       " ((2, 4), 0.46),\n",
       " ((2, 5), 0.55),\n",
       " ((3, 3), 1.0),\n",
       " ((3, 4), 0.5),\n",
       " ((3, 5), 0.53),\n",
       " ((4, 4), 1.0),\n",
       " ((4, 5), 0.54),\n",
       " ((5, 5), 1.0)]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_of_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
