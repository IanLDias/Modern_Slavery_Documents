{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path as pathl\n",
    "from pdf_parser import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append relevant file paths\n",
    "new_path = pathl('.')\n",
    "parent = new_path.resolve().parent\n",
    "sys.path.append(str(parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.walk(sys.path[-1] + '/Data')\n",
    "files = []\n",
    "for file in current_dir:\n",
    "    files.append(file[-1])\n",
    "files = sum(files, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = parent / 'Data'\n",
    "def get_text(filename):\n",
    "    'Return text from a filename'\n",
    "    pdf_file = data_path / filename\n",
    "    text_dict = pipeline(filepath = str(pdf_file))\n",
    "    text = list(text_dict.values())\n",
    "    text = sum(text, [])\n",
    "    text = [sentence.strip() for sentence in text]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def lemmatizer(text):\n",
    "    'Lemmatizes text'\n",
    "    doc = nlp.pipe(text)\n",
    "    lemmatized = []\n",
    "    for sentence in doc:\n",
    "        sent = []\n",
    "        for word in sentence:\n",
    "            if str(word) in punctuation:\n",
    "                continue\n",
    "            lemma = word.lemma_.strip() \n",
    "            sent.append(lemma)\n",
    "        \n",
    "        lemmatized.append(' '.join(sent))\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "corpus = []\n",
    "for file in files:\n",
    "    if file[-3:] == 'pdf':\n",
    "        text = get_text(file)\n",
    "        text = text.split('.')\n",
    "        lemmatized = lemmatizer(text)\n",
    "        corpus.append(' '.join(lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vectorizer.fit_transform(corpus)\n",
    "dense = model.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62116493]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(model[0], model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64637026]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(model[0], model[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64236199]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(model[1], model[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'https://www.qantas.com/content/dam/qantas/pdfs/about-us/corporate-governance/modern-slavery-and-human-trafficking-statement.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '[^/]+(\\.pdf)'\n",
    "match = re.search(pattern, url_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modern-slavery-and-human-trafficking-statement.pdf'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pdf'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match[0][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(download_url, filename):\n",
    "    response = urllib.request.urlopen(download_url)\n",
    "    if filename[-3:] == 'pdf':\n",
    "        file = open(filename, 'wb')\n",
    "    else:\n",
    "        file = open(filename + \".pdf\", 'wb')\n",
    "    file.write(response.read())\n",
    "    file.close()\n",
    "\n",
    "pattern = '[^/]+(\\.pdf)'  \n",
    "for url in url_list[:1]:\n",
    "    match = re.search(pattern, url)\n",
    "    title = match[0]\n",
    "    download_file(url, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '.*(\\.pdf)' \n",
    "match = re.search(pattern, url_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.orica.com/ArticleDocuments/311/20200712_Orica_Modern_Slavery_Statement.pdf'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://modernslaveryregister.gov.au/statements/file/cba2a76f-4097-458d-8195-11f4c56aedb7/'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
